{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix\n",
    "import igraph as ig\n",
    "import xnetwork as xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = \"debate2024_Jun_mastodon\"\n",
    "dataPath = Path(\"Data\")\n",
    "networksPath = dataPath/\"Networks\"\n",
    "networksPath.mkdir(parents=True, exist_ok=True)\n",
    "# Minimum number of activities for a user to be considered\n",
    "minUserActivities = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(dataPath / f\"{datasetName}.feather.gz\", 'rb') as f:\n",
    "    df = pd.read_feather(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userActivityCount = df[\"user_id\"].value_counts()\n",
    "usersWithMinActivities = set(userActivityCount[userActivityCount >= minUserActivities].index)\n",
    "dfFiltered = df[df[\"user_id\"].isin(usersWithMinActivities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainBipartiteEdgesHashtags(df,removeRetweets=True,removeReplies=False):\n",
    "    if \"hashtags\" not in df or \"post_type\" not in df or \"user_id\" not in df:\n",
    "        return []\n",
    "    \n",
    "    if(removeRetweets):\n",
    "        df = df[df[\"post_type\"] != \"repost\"]\n",
    "    if(removeReplies):\n",
    "        df = df[df[\"post_type\"] != \"reply\"]\n",
    "\n",
    "    # convert url strings that looks like lists to actual lists\n",
    "    users = df[\"user_id\"]\n",
    "    hashtags = df[\"hashtags\"].apply(lambda hashtagList: [hashtag.lower().strip() for hashtag in hashtagList])\n",
    "    # keep only non-empty lists\n",
    "    mask = hashtags.apply(lambda x: len(x) > 0)\n",
    "    hashtags = hashtags[mask]\n",
    "    users = users[mask]\n",
    "    # create edges list users -> hashtags\n",
    "    edges = [(user,hashtag) for user,hashtag_list in zip(users,hashtags) for hashtag in hashtag_list]\n",
    "    return edges\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartiteEdges = obtainBipartiteEdgesHashtags(dfFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterNodes(bipartiteEdges, minRightDegree=1, minLeftDegree=1):\n",
    "    # goes from right to left\n",
    "    bipartiteEdges = np.array(bipartiteEdges)\n",
    "    mask = np.ones(len(bipartiteEdges),dtype=bool)\n",
    "    if(minRightDegree>1):\n",
    "        uniqueEdges = set(tuple(edge) for edge in bipartiteEdges)\n",
    "        uniqueEdges = np.array(list(uniqueEdges))\n",
    "        rightDegrees = Counter(uniqueEdges[:,1])\n",
    "        mask &= np.array([rightDegrees[rightNode]>=minRightDegree for _,rightNode in bipartiteEdges])\n",
    "    bipartiteEdges = bipartiteEdges[mask]\n",
    "    \n",
    "    # goes from left to right\n",
    "    mask = np.ones(len(bipartiteEdges),dtype=bool)\n",
    "    if(minLeftDegree>1):\n",
    "        uniqueEdges = set(tuple(edge) for edge in bipartiteEdges)\n",
    "        uniqueEdges = np.array(list(uniqueEdges))\n",
    "        leftDegrees = Counter(uniqueEdges[:,0])\n",
    "        mask &= np.array([leftDegrees[leftNode]>=minLeftDegree for leftNode,_ in bipartiteEdges])\n",
    "    bipartiteEdges = bipartiteEdges[mask]\n",
    "    return bipartiteEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartiteEdges = filterNodes(bipartiteEdges, minRightDegree=4, minLeftDegree=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert left and right for cooccurrence graph\n",
    "bipartiteEdges = [(right,left) for left,right in bipartiteEdges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartiteEdges = np.array(bipartiteEdges)\n",
    "bipartiteIndexedEdges = np.zeros(bipartiteEdges.shape, dtype=int)\n",
    "leftIndex2Label = [label for label in np.unique(bipartiteEdges[:,0])]\n",
    "leftLabel2Index = {label: index for index, label in enumerate(leftIndex2Label)}\n",
    "rightIndex2Label = [label for label in np.unique(bipartiteEdges[:,1])]\n",
    "rightLabel2Index = {label: index for index, label in enumerate(rightIndex2Label)}\n",
    "\n",
    "# create indexed edges in a numpy array integers\n",
    "bipartiteIndexedEdges[:,0] = [leftLabel2Index[label] for label in bipartiteEdges[:,0]]\n",
    "bipartiteIndexedEdges[:,1] = [rightLabel2Index[label] for label in bipartiteEdges[:,1]]\n",
    "\n",
    "leftCount = len(leftIndex2Label)\n",
    "rightCount = len(rightIndex2Label)\n",
    "\n",
    "leftIndexedDegree = np.bincount(bipartiteIndexedEdges[:,0])\n",
    "rightIndexedDegree = np.bincount(bipartiteIndexedEdges[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bipartiteIndexedEdges[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsMatrix = csr_matrix((np.ones(len(bipartiteIndexedEdges)), (bipartiteIndexedEdges[:,0], bipartiteIndexedEdges[:,1])), shape=(leftCount, rightCount))\n",
    "vectorizer = TfidfTransformer()\n",
    "# weightsMatrix = vectorizer.fit_transform(weightsMatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(weightsMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a threshold to the similarities\n",
    "threshold = 0.4\n",
    "similarities[similarities<threshold] = 0\n",
    "# remove diagonal\n",
    "np.fill_diagonal(similarities, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ig.Graph.Weighted_Adjacency(similarities, mode=\"undirected\", attr=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"Number of nodes\":g.vcount(),\n",
    " \"Number of edges\":g.ecount(),\n",
    " \"Avg. degree\": 2.0*g.ecount()/g.vcount()\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.vs[\"Label\"] = leftIndex2Label\n",
    "# original number of posts\n",
    "g.vs[\"UserCount\"] = leftIndexedDegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove isolated nodes\n",
    "gFiltered = g.subgraph(g.vs.select(_degree_gt=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "   \"Number of nodes\":gFiltered.vcount(),\n",
    "   \"Number of edges\":gFiltered.ecount(),\n",
    "   \"Avg. degree\": 2.0*gFiltered.ecount()/gFiltered.vcount()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to XNET\n",
    "xn.save(gFiltered, networksPath/f\"{datasetName}_hashtag_cooccurence.xnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save largest connected component\n",
    "gLCC = gFiltered.components().giant()\n",
    "xn.save(gLCC, networksPath/f\"{datasetName}_hashtag_cooccurence_giant.xnet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ic2s2_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
